# rul_model_trainer_all_sets.py (Spearman ê°œì„ : ë‚®ì€ threshold + ìƒìœ„ Nê°œ ì„ íƒ + ë‹¤ì±„ë„)
'''
ì±„ë„ 4ê°œ(CH1 ~ CH4) â†’ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ê²°í•©í–ˆëŠ”ê°€?

### ê²°í•© ë°©ì‹

ê° ì±„ë„ì—ì„œ ì¶”ì¶œí•œ íŠ¹ì§•ë“¤ì„ **í•˜ë‚˜ì˜ ë²¡í„°**ë¡œ **ë³‘ë ¬ ê²°í•©(concatenate)**í•©ë‹ˆë‹¤.

CH1_mean, CH1_std, CH1_entropy, ..., CH4_band_power, CH4_entropy

â€”>>>>>>ê·¸ë ‡ë‹¤ë©´ ì—”íŠ¸ë¡œí”¼ì˜ ë¹„ì¤‘ì´ ë‚®ìœ¼ë¯€ë¡œ í‚¤ìš°ì( ì—”íŠ¸ë¡œí”¼ê°’ *3)
->>>>>> chë³„ ìƒìœ„ 10ê°œ ì¶”ì¶œ
->>>>>> ì´ˆë‹¨ìœ„ ë¼ë²¨ë§
'''
import os
import numpy as np
import pandas as pd
from glob import glob
from scipy.stats import kurtosis, skew, spearmanr
from scipy.signal import welch
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from nptdms import TdmsFile

# â–¶ Spearman ê¸°ë°˜ ì„ íƒëœ ì£¼íŒŒìˆ˜ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
SELECTED_FREQ_INDICES = {}
FREQ_VECTOR = None

# â–¶ ì§„ë™ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_vibration_data(file_path):
    tdms_file = TdmsFile.read(file_path)
    group_name = tdms_file.groups()[0].name  # ì§„ë™ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” ì²« ê·¸ë£¹
    vib_channels = tdms_file[group_name].channels()
    vib_data = {ch.name: ch.data for ch in vib_channels}
    return pd.DataFrame(vib_data)

# â–¶ ì‹œê°„ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜
def extract_timestamp(f):
    name = os.path.basename(f)
    time_part = name.split("_")[-1].replace(".tdms", "")
    return pd.to_datetime(time_part, format="%Y%m%d%H%M%S")

# â–¶ Spearman ê¸°ë°˜ ì£¼íŒŒìˆ˜ ì„ íƒ í•¨ìˆ˜ (ìƒìœ„ Nê°œ ê³ ì •)
def compute_selected_frequency_indices(file_list, channels, top_n=10, sampling_rate=25600):
    psd_by_channel = {ch: [] for ch in channels}
    rul_list = []

    for file_path, rul in file_list:
        df = load_vibration_data(file_path)
        if df.empty:
            continue
        for ch in channels:
            if ch not in df.columns:
                continue
            data = df[ch].values
            f, Pxx = welch(data, fs=sampling_rate)
            psd_by_channel[ch].append(Pxx)
        rul_list.append(rul)

    selected = {}
    for ch in channels:
        psd_matrix = np.array(psd_by_channel[ch])
        if psd_matrix.shape[0] == 0:
            continue
        rho_list = [abs(spearmanr(psd_matrix[:, i], rul_list)[0]) for i in range(psd_matrix.shape[1])]
        top_indices = np.argsort(rho_list)[-top_n:]  # ìƒìœ„ Nê°œ ì„ íƒ
        selected[ch] = top_indices.tolist()

    print(f" Spearman ê¸°ë°˜ ì£¼íŒŒìˆ˜ ì„ íƒ ì™„ë£Œ (ì±„ë„ë³„ {top_n}ê°œ)")
    return selected, f

# â–¶ ì—ë„ˆì§€ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° í•¨ìˆ˜ (ì„ íƒëœ ì£¼íŒŒìˆ˜ ê¸°ë°˜)
def energy_entropy_selected(data, selected_indices, sampling_rate=25600):
    f, Pxx = welch(data, fs=sampling_rate)
    selected = Pxx[selected_indices]
    selected = selected / np.sum(selected)
    selected = selected[selected > 0]
    return -np.sum(selected * np.log(selected))

# â–¶ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def extract_features_from_vibration(vib_df, sampling_rate=25600):
    features = {}
    for ch in vib_df.columns:
        data = vib_df[ch].values
        rms = np.sqrt(np.mean(data**2))
        f, Pxx = welch(data, fs=sampling_rate)

        features[f'{ch}_mean'] = np.mean(data)
        features[f'{ch}_std'] = np.std(data)
        features[f'{ch}_rms'] = rms
        features[f'{ch}_kurtosis'] = kurtosis(data)
        features[f'{ch}_skew'] = skew(data)
        features[f'{ch}_crest'] = np.max(np.abs(data)) / rms
        features[f'{ch}_band_power'] = np.sum(Pxx)

        if ch in SELECTED_FREQ_INDICES:
            features[f'{ch}_entropy'] = energy_entropy_selected(data, SELECTED_FREQ_INDICES[ch], sampling_rate)*3

    return features

# â–¶ ì „ì²´ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
def process_all_sets(top_folder):
    global SELECTED_FREQ_INDICES, FREQ_VECTOR
    all_rows = []
    rul_pairs = []
    channels = ["CH1", "CH2", "CH3", "CH4"]
    set_folders = sorted([os.path.join(top_folder, d) for d in os.listdir(top_folder) if os.path.isdir(os.path.join(top_folder, d))])

    for set_path in set_folders:
        tdms_files = sorted(glob(os.path.join(set_path, "*.tdms")), key=extract_timestamp)
        if not tdms_files:
            print(f"âš ï¸ {set_path} í´ë”ì— .tdms íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue  # ì´ í´ë”ëŠ” ê±´ë„ˆëœ€
        
        file_times = [extract_timestamp(f) for f in tdms_files]
        end_time = max(file_times)

        for file_path, ts in zip(tdms_files, file_times):
            rul = (end_time - ts).total_seconds()  # ğŸ”¥ ì´ˆ ë‹¨ìœ„ RUL
            rul_pairs.append((file_path, rul))


    SELECTED_FREQ_INDICES, FREQ_VECTOR = compute_selected_frequency_indices(rul_pairs, channels, top_n=10)

    for file_path, rul in rul_pairs:
        try:
            vib_df = load_vibration_data(file_path)
            if vib_df.empty:
                continue
            features = extract_features_from_vibration(vib_df)
            features['file'] = os.path.basename(file_path)
            features['RUL'] = rul
            all_rows.append(features)
        except Exception as e:
            print(f" ì˜¤ë¥˜ ë°œìƒ: {file_path} - {e}")

    return pd.DataFrame(all_rows)

# â–¶ ì‹œí€€ìŠ¤ êµ¬ì„± í•¨ìˆ˜
def create_sequences(X, y, window_size=5):
    X_seq, y_seq = [], []
    for i in range(len(X) - window_size + 1):
        X_seq.append(X[i:i+window_size])
        y_seq.append(y[i + window_size - 1])
    return np.array(X_seq), np.array(y_seq)

# â–¶ ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":
    DATA_ROOT = r"c:/Users/ì¡°ì„±ì°¬/OneDrive - UOS/ë°”íƒ• í™”ë©´/ë°°ì–´ë§ë°ì´í„°"

    print("\n ì§„ë™ íŠ¹ì§• ì¶”ì¶œ ë° RUL ìƒì„± ì¤‘...")
    full_df = process_all_sets(DATA_ROOT)

    if full_df.empty:
        print(" full_dfê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        exit()

    print("\n ìŠ¤ì¼€ì¼ë§ ë° ì‹œí€€ìŠ¤ êµ¬ì„± ì¤‘...")
    scaler = MinMaxScaler()
    X_all = scaler.fit_transform(full_df.drop(columns=["RUL", "file"]))
    y_all = full_df["RUL"].values

    X_seq, y_seq = create_sequences(X_all, y_all, window_size=5)
    X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)

    print("\n LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model = Sequential([
        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mae')
    model.fit(X_train, y_train, epochs=5000, batch_size=16, validation_data=(X_val, y_val))

    pred = model.predict(X_val)
    print("\n í‰ê°€ ê²°ê³¼:")
    print("MAE:", mean_absolute_error(y_val, pred))
    print("RÂ²:", r2_score(y_val, pred))

    model.save("rul_lstm_all_sets.h5")
    print("\nëª¨ë¸ì´ rul_lstm_all_sets.h5ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")