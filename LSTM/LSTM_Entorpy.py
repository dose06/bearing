# rul_model_trainer_all_sets.py
'''
ì§„ë™ ë°ì´í„° (ì‹œê°„ íë¦„)

â†“
FFT â†’ ì£¼íŒŒìˆ˜ë³„ ì§„í­

**(ì§„ë™ ì‹ í˜¸ëŠ” ì‹œê°„ ë„ë©”ì¸ì—ì„œì˜ íŒŒí˜•ì¸ë°, ì´ê±¸ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ìœ¼ë¡œ ë°”ê¾¸ë©´, ì–´ë–¤ ì£¼íŒŒìˆ˜ì— ì—ë„ˆì§€ê°€ ì–¼ë§ˆë‚˜ ë¶„í¬ë¼ ìˆëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìŒ)**

â†“
ì •ê·œí™”ëœ ì£¼íŒŒìˆ˜ ì—ë„ˆì§€

â†“
ì„ íƒëœ ì£¼íŒŒìˆ˜ (Spearman ìƒê´€â†“)

â†“
ì •ë³´ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ì—ë„ˆì§€ ì—”íŠ¸ë¡œí”¼)

â†“
ë‹¨ì¡° ê°ì†Œí•˜ëŠ” íŠ¹ì§• ì‹ í˜¸

â†“
â†’ ìˆ˜ëª… ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥(RUL Regression Target)

Spearman ë„ì… x
'''
import os
import numpy as np
import pandas as pd
from glob import glob
from scipy.stats import kurtosis, skew
from scipy.signal import welch
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# ì—ë„ˆì§€ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° í•¨ìˆ˜
def energy_entropy(data, sampling_rate=25600, n_bins=100):
    f, Pxx = welch(data, fs=sampling_rate)
    Pxx = Pxx / np.sum(Pxx)  # ì •ê·œí™”
    Pxx = Pxx[Pxx > 0]  # ë¡œê·¸ 0 ë°©ì§€
    entropy = -np.sum(Pxx * np.log(Pxx))
    return entropy

#  ì§„ë™ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜

def extract_features_from_vibration(vib_df, sampling_rate=25600):
    features = {}
    for ch in vib_df.columns:
        data = vib_df[ch].values
        rms = np.sqrt(np.mean(data**2))
        f, Pxx = welch(data, fs=sampling_rate)

        features[f'{ch}_mean'] = np.mean(data)
        features[f'{ch}_std'] = np.std(data)
        features[f'{ch}_rms'] = rms
        features[f'{ch}_kurtosis'] = kurtosis(data)
        features[f'{ch}_skew'] = skew(data)
        features[f'{ch}_crest'] = np.max(np.abs(data)) / rms
        features[f'{ch}_band_power'] = np.sum(Pxx)
        features[f'{ch}_entropy'] = energy_entropy(data, sampling_rate)
    return features

#  TDMS íŒŒì¼ì—ì„œ ì§„ë™ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
from nptdms import TdmsFile

def load_vibration_data(file_path):
    tdms_file = TdmsFile.read(file_path)
    group_name = tdms_file.groups()[0].name  # Vibration group
    vib_channels = tdms_file[group_name].channels()
    vib_data = {ch.name: ch.data for ch in vib_channels}
    return pd.DataFrame(vib_data)

def extract_timestamp(f):
    name = os.path.basename(f)
    time_part = name.split("_")[-1].replace(".tdms", "")  # "20160325122639"
    return pd.to_datetime(time_part, format="%Y%m%d%H%M%S")

# ë©”ì¸: íŠ¹ì • + RUL ìƒì„± + í•˜ë‚˜ë¡œ í†µí•©

def process_all_sets(top_folder):
    all_rows = []
    set_folders = sorted([os.path.join(top_folder, d) for d in os.listdir(top_folder) if os.path.isdir(os.path.join(top_folder, d))])

    for set_path in set_folders:
        print(f"\nì²˜ë¦¬ ì¤‘ì¸ í´ë”: {set_path}")
        tdms_files = sorted(glob(os.path.join(set_path, "*.tdms")), key=extract_timestamp)
        if not tdms_files:
            print("   .tdms íŒŒì¼ ì—†ìŒ â†’ ê±´ë„ˆëœ€")
            continue

        total_files = len(tdms_files)
        print(f"   ì´ {total_files}ê°œ íŒŒì¼ ë°œê²¬")

        for i, file_path in enumerate(tdms_files):
            print(f"     íŒŒì¼ {i+1}: {os.path.basename(file_path)}")
            try:
                vib_df = load_vibration_data(file_path)
                print(f"      ğŸ”¹ ì±„ë„ ìˆ˜: {vib_df.shape[1]}ê°œ / ìƒ˜í”Œ ìˆ˜: {vib_df.shape[0]}")
                print(f"      ğŸ”¹ ì±„ë„ ëª©ë¡: {vib_df.columns.tolist()}")

                if vib_df.empty:
                    print(f"      ë°ì´í„° ë¹„ì–´ìˆìŒ â†’ ê±´ë„ˆëœ€")
                    continue

                features = extract_features_from_vibration(vib_df)
                features['file'] = os.path.basename(file_path)
                features['RUL'] = (total_files - 1 - i) * 10
                all_rows.append(features)

            except Exception as e:
                print(f"       ì˜¤ë¥˜ ë°œìƒ: {file_path}")
                print("         ì´ìœ :", str(e))

    return pd.DataFrame(all_rows)

#  ì‹œí€€ìŠ¤ êµ¬ì„± í•¨ìˆ˜
def create_sequences(X, y, window_size=5):
    X_seq, y_seq = [], []
    for i in range(len(X) - window_size + 1):
        X_seq.append(X[i:i+window_size])
        y_seq.append(y[i + window_size - 1])
    return np.array(X_seq), np.array(y_seq)

#  í”„ë¡œì„¸ìŠ¤ ì‹œì‘
if __name__ == "__main__":
    DATA_ROOT = r"c:/Users/ì¡°ì„±ì°¬/OneDrive - UOS/ë°”íƒ• í™”ë©´/ë°°ì–´ë§ë°ì´í„°"

    print("\n ì§„ë™ íŠ¹ì§• ì¶”ì¶œ ë° RUL ìƒì„± ì¤‘...")
    full_df = process_all_sets(DATA_ROOT)
    # full_df ê²€ì¦ ì¶”ê°€
    if full_df.empty:
        print(" full_dfê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì§„ë™ ë°ì´í„°ì—ì„œ ì•„ë¬´ íŠ¹ì§•ë„ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()

    missing = [col for col in ["RUL", "file"] if col not in full_df.columns]
    if missing:
        print(f" full_dfì— ë‹¤ìŒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        print(" í˜„ì¬ ì»¬ëŸ¼ ëª©ë¡:", full_df.columns.tolist())
        print(" ì´ìœ : íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì¼ë¶€ tdmsê°€ ì—´ë¦¬ì§€ ì•Šì•˜ê±°ë‚˜ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        exit()

    print("\n ìŠ¤ì¼€ì¼ë§ ë° ì‹œí€€ìŠ¤ êµ¬ì„± ì¤‘...")
    scaler = MinMaxScaler()
    X_all = scaler.fit_transform(full_df.drop(columns=["RUL", "file"]))
    y_all = full_df["RUL"].values
    print("\n full_df ë‚´ìš© í™•ì¸:")
    print(full_df.head())
    print("\n full_df ì»¬ëŸ¼ ëª©ë¡:")
    print(full_df.columns.tolist())
    print("\n full_df ì „ì²´ í–‰ ìˆ˜:", len(full_df))
    X_seq, y_seq = create_sequences(X_all, y_all, window_size=5)

    X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)

    print("\n LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model = Sequential([
        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mae')
    model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_val, y_val))

    pred = model.predict(X_val)
    print("\n í‰ê°€ ê²°ê³¼:")
    print("MAE:", mean_absolute_error(y_val, pred))
    print("RÂ²:", r2_score(y_val, pred))

    model.save("rul_lstm_all_sets.h5")
    print("\nëª¨ë¸ì´ rul_lstm_all_sets.h5ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")